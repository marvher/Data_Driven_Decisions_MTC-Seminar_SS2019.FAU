{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepVis_TransferLearning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da1962502aaf4b06b6f7a285fe8f571c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_options_labels": [
              "VicNet",
              "ResNet18",
              "VGG16",
              "RegNet",
              "BaseNet",
              "MaxNet"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_769563887a7a44c7a65728dbfaa5aa5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "DropdownModel",
            "index": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15ec4fe9bb4d4e878da1ec7d69e5e0f3"
          }
        },
        "769563887a7a44c7a65728dbfaa5aa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15ec4fe9bb4d4e878da1ec7d69e5e0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marvher/Data_Driven_Decisions_MTC-Seminar_SS2019.FAU/blob/main/DeepVis_IMAGE_CLASSIFICATION_SWEEPS_noEarly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhfYsYKKOShL"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP2mw1s2lkES"
      },
      "source": [
        "## Weights & Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abULiS8OOW_K"
      },
      "source": [
        "%%capture \n",
        "!pip install wandb --upgrade"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1gbgcRAOape",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4540f5f9-7269-4690-c6e2-14354a7f5030"
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarvher\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtdqVvLyqYib"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'loss',\n",
        "      'goal': 'minimize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values': [50, 100, 200]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [256, 128, 64, 32]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.3, 0.5, 0.7]\n",
        "        },\n",
        "        'kernel_size': {\n",
        "            'values': [3, 5, 7]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\n",
        "        },\n",
        "        'fc_layer_size':{\n",
        "            'values':[128, 256, 512]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'sgd', 'adadelta']\n",
        "        },\n",
        "    }\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "AHgYMbNascgj",
        "outputId": "9bc0ff30-f0ee-471e-c857-b1b21ca31760"
      },
      "source": [
        "# Default values for hyper-parameters we're going to sweep over\n",
        "config_defaults = {\n",
        "    'epochs': 5,\n",
        "    'batch_size': 128,\n",
        "    'learning_rate': 1e-3,\n",
        "    'optimizer': 'adam',\n",
        "    'fc_layer_size': 128,\n",
        "    'dropout': 0.5,\n",
        "    'kernel_size': 3\n",
        "}\n",
        "\n",
        "# # Initialize a new wandb run\n",
        "wandb.init(project='waferimages-sweeps', entity='inceptioneers', config=config_defaults)\n",
        "\n",
        "# # Config is a variable that holds and saves hyperparameters and inputs\n",
        "config = wandb.config"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.0<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lilac-waterfall-462</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/inceptioneers/waferimages-sweeps\" target=\"_blank\">https://wandb.ai/inceptioneers/waferimages-sweeps</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/inceptioneers/waferimages-sweeps/runs/1a1g4uyn\" target=\"_blank\">https://wandb.ai/inceptioneers/waferimages-sweeps/runs/1a1g4uyn</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210817_203144-1a1g4uyn</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2xTxQeKqjiE",
        "outputId": "d1ed6589-d465-4c97-ab4d-2b5e9837991d"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='waferimages-sweeps', entity='inceptioneers')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: nygp64a8\n",
            "Sweep URL: https://wandb.ai/inceptioneers/waferimages-sweeps/sweeps/nygp64a8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOuSpg0Iylfc"
      },
      "source": [
        "# 1. Start a new run\n",
        "#wandb.init(project='waferimages', entity='inceptioneers', config=config)\n",
        "\n",
        "# 2. Save model inputs and hyperparameters\n",
        "#config = wandb.config"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-9Tl-RFlz6_"
      },
      "source": [
        "## Libraries & Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3F2Y50clwfU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "#import cv2\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from imutils import paths\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import copy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFOgfCKiDQ9n"
      },
      "source": [
        "The next block of code applies a seed to our code for reproducibility and also sets the computation device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7IK0e8DOj0",
        "outputId": "d8b1b032-a6ad-4de4-cff6-4b6acdc0bfbb"
      },
      "source": [
        "def seed_libraries(SEED=42):\n",
        "  # Python seeds\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  # Torch seeds\n",
        "  torch.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "SEED=42\n",
        "seed_libraries(SEED=SEED)\n",
        "\n",
        "\n",
        "# set computation device\n",
        "runtime = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Computation device: {runtime}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computation device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-un7U53amuuz"
      },
      "source": [
        "# **Set Dicitonaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-a88VYLm0Ya"
      },
      "source": [
        "**Google Drive Version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPPN1MqumuRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d442c00f-bb0b-465b-8edc-ef5f8b446c7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-lDCvDGoeJV"
      },
      "source": [
        "# !unzip /content/drive/MyDrive/data.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDj_9b9Sm9RM"
      },
      "source": [
        "DIR_DATEN = \"/content/drive/MyDrive/DEEPVIS/data\"   # make sure to always adapt this to your own folser structure\n",
        "DIR_DATEN_01 = os.path.join(DIR_DATEN, \"01_Daten\")\n",
        "DIR_WAFER_IMAGES = os.path.join(DIR_DATEN, \"WaferImages\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCZ10w5ODGv"
      },
      "source": [
        "## **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3V0mipE82yk"
      },
      "source": [
        "labels_filename =\"Labels_Waferviertel.xlsx\"\n",
        "meta_filename = \"Meta_data.csv\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIpv38AzOIAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "c6d2607a-2d3b-4bf8-fb81-2fd1fb17fc35"
      },
      "source": [
        "labels = pd.read_excel(os.path.join(DIR_DATEN_01, labels_filename))\n",
        "labels.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Part No</th>\n",
              "      <th>Crack</th>\n",
              "      <th>Patch</th>\n",
              "      <th>Scratch</th>\n",
              "      <th>Low Level</th>\n",
              "      <th>Circle</th>\n",
              "      <th>Displaced</th>\n",
              "      <th>Splinter</th>\n",
              "      <th>Stain</th>\n",
              "      <th>Wafer on Pin</th>\n",
              "      <th>Other</th>\n",
              "      <th>PosX</th>\n",
              "      <th>PosY</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>PreviousClass</th>\n",
              "      <th>NoOfErrors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001932631.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:45</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001945868.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-06-12 13:48:47</td>\n",
              "      <td>other</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       File Name  Part No  Crack  ...            Timestamp  PreviousClass  NoOfErrors\n",
              "0  001932631.tif        0  False  ...  2019-06-12 13:48:45          other           1\n",
              "1  001932631.tif        1  False  ...  2019-06-12 13:48:45          other           1\n",
              "2  001932631.tif        2  False  ...  2019-06-12 13:48:45          other           1\n",
              "3  001932631.tif        3  False  ...  2019-06-12 13:48:45          other           1\n",
              "4  001945868.tif        0  False  ...  2019-06-12 13:48:47          other           1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFUdpMtCOJ_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91612986-0d58-4428-84a8-89c646741a61"
      },
      "source": [
        "labels[\"PreviousClass\"].unique()  # we don't need that any longer?"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['other', 'patch', 'circle', 'splinter', 'stain', 'waferonpin',\n",
              "       'crack', 'scratch'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHsIgaSOMoA"
      },
      "source": [
        "## **Meta-Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQymXrZ1OQK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "e314eee5-0c50-49ca-d1ee-cab99e3dce55"
      },
      "source": [
        "meta = pd.read_csv(os.path.join(DIR_DATEN_01, meta_filename))\n",
        "meta"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>wafer_id</th>\n",
              "      <th>gray_mean</th>\n",
              "      <th>class</th>\n",
              "      <th>NameBild</th>\n",
              "      <th>SUBSTRATEIDENT</th>\n",
              "      <th>TIMESTAMP_CTS</th>\n",
              "      <th>CTS_EFF</th>\n",
              "      <th>CTS_FF</th>\n",
              "      <th>CTS_VOC</th>\n",
              "      <th>CTS_ISC</th>\n",
              "      <th>CTS_RSER</th>\n",
              "      <th>CTS_RSH</th>\n",
              "      <th>CTS_IREV2_T</th>\n",
              "      <th>CTS_B2B_1</th>\n",
              "      <th>CTS_JOB_NR</th>\n",
              "      <th>CTS_EL_CRACK_COUNT</th>\n",
              "      <th>CTS_EL_DARKAREA_COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002152418.tif</td>\n",
              "      <td>2152418</td>\n",
              "      <td>183.47</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>002152418.tif</td>\n",
              "      <td>11790109.0</td>\n",
              "      <td>2018-07-26 14:46:26</td>\n",
              "      <td>23.136937</td>\n",
              "      <td>0.814332</td>\n",
              "      <td>737.587</td>\n",
              "      <td>9.412589</td>\n",
              "      <td>4.987</td>\n",
              "      <td>4481.251483</td>\n",
              "      <td>0.331505</td>\n",
              "      <td>20.010000</td>\n",
              "      <td>20180726 Exp 66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001889692.tif</td>\n",
              "      <td>1889692</td>\n",
              "      <td>176.80</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001889692.tif</td>\n",
              "      <td>11232718.0</td>\n",
              "      <td>2018-02-27 13:19:22</td>\n",
              "      <td>23.041940</td>\n",
              "      <td>0.810728</td>\n",
              "      <td>735.176</td>\n",
              "      <td>9.445444</td>\n",
              "      <td>5.032</td>\n",
              "      <td>3471.378009</td>\n",
              "      <td>0.040560</td>\n",
              "      <td>35.639999</td>\n",
              "      <td>20180227 HD556</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001897005.tif</td>\n",
              "      <td>1897005</td>\n",
              "      <td>177.04</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001897005.tif</td>\n",
              "      <td>11278998.0</td>\n",
              "      <td>2018-03-05 15:07:20</td>\n",
              "      <td>23.073799</td>\n",
              "      <td>0.811632</td>\n",
              "      <td>735.720</td>\n",
              "      <td>9.441592</td>\n",
              "      <td>4.906</td>\n",
              "      <td>3821.416372</td>\n",
              "      <td>0.021333</td>\n",
              "      <td>38.169998</td>\n",
              "      <td>20180305 HD547-4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001962325.tif</td>\n",
              "      <td>1962325</td>\n",
              "      <td>172.97</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>001962325.tif</td>\n",
              "      <td>11403759.0</td>\n",
              "      <td>2018-04-04 11:41:30</td>\n",
              "      <td>22.571537</td>\n",
              "      <td>0.797088</td>\n",
              "      <td>734.655</td>\n",
              "      <td>9.417174</td>\n",
              "      <td>5.329</td>\n",
              "      <td>3016.940429</td>\n",
              "      <td>0.006562</td>\n",
              "      <td>38.720001</td>\n",
              "      <td>20180328 M2R</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002152288.tif</td>\n",
              "      <td>2152288</td>\n",
              "      <td>173.58</td>\n",
              "      <td>Cracks</td>\n",
              "      <td>002152288.tif</td>\n",
              "      <td>11794609.0</td>\n",
              "      <td>2018-07-26 14:34:30</td>\n",
              "      <td>23.001560</td>\n",
              "      <td>0.810923</td>\n",
              "      <td>735.170</td>\n",
              "      <td>9.428756</td>\n",
              "      <td>5.170</td>\n",
              "      <td>1169.261436</td>\n",
              "      <td>0.182121</td>\n",
              "      <td>20.059999</td>\n",
              "      <td>20180726 Exp 66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6101</th>\n",
              "      <td>002126113.tif</td>\n",
              "      <td>2126113</td>\n",
              "      <td>213.27</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002126113.tif</td>\n",
              "      <td>11734418.0</td>\n",
              "      <td>2018-07-02 11:44:45</td>\n",
              "      <td>23.665103</td>\n",
              "      <td>0.821231</td>\n",
              "      <td>744.152</td>\n",
              "      <td>9.462665</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4500.504749</td>\n",
              "      <td>0.009221</td>\n",
              "      <td>43.840000</td>\n",
              "      <td>20180702 EXP41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>002160320.tif</td>\n",
              "      <td>2160320</td>\n",
              "      <td>172.81</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002160320.tif</td>\n",
              "      <td>11825342.0</td>\n",
              "      <td>2018-08-02 10:34:09</td>\n",
              "      <td>22.769944</td>\n",
              "      <td>0.800344</td>\n",
              "      <td>734.057</td>\n",
              "      <td>9.471267</td>\n",
              "      <td>5.318</td>\n",
              "      <td>25349.092305</td>\n",
              "      <td>0.000851</td>\n",
              "      <td>19.879999</td>\n",
              "      <td>20180802 EXP 99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6103</th>\n",
              "      <td>002161033.tif</td>\n",
              "      <td>2161033</td>\n",
              "      <td>201.44</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161033.tif</td>\n",
              "      <td>11827179.0</td>\n",
              "      <td>2018-08-02 11:35:48</td>\n",
              "      <td>23.229798</td>\n",
              "      <td>0.811132</td>\n",
              "      <td>740.253</td>\n",
              "      <td>9.453416</td>\n",
              "      <td>4.889</td>\n",
              "      <td>14218.466321</td>\n",
              "      <td>0.001039</td>\n",
              "      <td>22.299999</td>\n",
              "      <td>20180802 EXP 99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6104</th>\n",
              "      <td>002161876.tif</td>\n",
              "      <td>2161876</td>\n",
              "      <td>194.77</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161876.tif</td>\n",
              "      <td>11807331.0</td>\n",
              "      <td>2018-08-03 12:47:42</td>\n",
              "      <td>23.060322</td>\n",
              "      <td>0.810989</td>\n",
              "      <td>736.246</td>\n",
              "      <td>9.435790</td>\n",
              "      <td>5.220</td>\n",
              "      <td>2525.808870</td>\n",
              "      <td>0.008307</td>\n",
              "      <td>26.870001</td>\n",
              "      <td>20180803 EXP 58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6105</th>\n",
              "      <td>002161769.tif</td>\n",
              "      <td>2161769</td>\n",
              "      <td>183.17</td>\n",
              "      <td>gute_Wafer</td>\n",
              "      <td>002161769.tif</td>\n",
              "      <td>11806845.0</td>\n",
              "      <td>2018-08-03 12:35:43</td>\n",
              "      <td>23.053969</td>\n",
              "      <td>0.812255</td>\n",
              "      <td>735.366</td>\n",
              "      <td>9.430334</td>\n",
              "      <td>4.984</td>\n",
              "      <td>3382.212480</td>\n",
              "      <td>0.019721</td>\n",
              "      <td>24.680000</td>\n",
              "      <td>20180803 EXP 58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6106 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_name  wafer_id  ...  CTS_EL_CRACK_COUNT CTS_EL_DARKAREA_COUNT\n",
              "0     002152418.tif   2152418  ...                 0.0                   0.0\n",
              "1     001889692.tif   1889692  ...                 1.0                   0.0\n",
              "2     001897005.tif   1897005  ...                 0.0                   0.0\n",
              "3     001962325.tif   1962325  ...                 1.0                   0.0\n",
              "4     002152288.tif   2152288  ...                 0.0                   0.0\n",
              "...             ...       ...  ...                 ...                   ...\n",
              "6101  002126113.tif   2126113  ...                 0.0                   0.0\n",
              "6102  002160320.tif   2160320  ...                 0.0                   0.0\n",
              "6103  002161033.tif   2161033  ...                 0.0                   0.0\n",
              "6104  002161876.tif   2161876  ...                 0.0                   0.0\n",
              "6105  002161769.tif   2161769  ...                 0.0                   0.0\n",
              "\n",
              "[6106 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6-xtJ2pOTm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dba7f99-7a24-45e8-bde5-5c2a5f9d958b"
      },
      "source": [
        "meta[\"class\"].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Cracks', 'Flecken', 'Kratzer', 'low_level', 'Punkte',\n",
              "       'schlecht_positioniert', 'Sonstiges', 'Splitter_im_Tester',\n",
              "       'Verschmutzung', 'Wafer_auf_Pin', 'gute_Wafer'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8saJb3ZOZE_"
      },
      "source": [
        "## **Load, Select and Encode Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTuXl_7GOdcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c80c30-51ae-49cd-e8c5-1bdd64219991"
      },
      "source": [
        "# get all the image paths\n",
        "image_paths = list(paths.list_images(DIR_WAFER_IMAGES))\n",
        "\n",
        "# create an empty DataFrame\n",
        "data = pd.DataFrame()\n",
        "\n",
        "for i, image_path in tqdm(enumerate(image_paths), total=len(image_paths)):\n",
        "    data.loc[i, 'label'] = image_path.split(os.path.sep)[-2]  # loading labels into DataFrame based on directory name\n",
        "    data.loc[i, 'image_path'] = image_path # loading image paths into DataFrame\n",
        "\n",
        "print(data.head())\n",
        "print('\\n')\n",
        "print(\"Unique classes: \", data.label.unique())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5944/5944 [00:04<00:00, 1258.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "       label                                         image_path\n",
            "0  displaced  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1  displaced  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "2  displaced  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "3  displaced  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "4  displaced  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "\n",
            "\n",
            "Unique classes:  ['displaced' 'low_level' 'crack' 'patch' 'scratch' 'circle' 'other'\n",
            " 'splinter' 'stain' 'waferonpin' 'good']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DTEpnmEVT0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c533566f-eaac-4e2d-f01b-3d52f63febdb"
      },
      "source": [
        "sel_classes = ['circle', 'crack', 'good', 'scratch', 'splinter', 'stain'] # selecting bounding boxes classes\n",
        "\n",
        "data = data[data['label'].isin(sel_classes)] # reducing DataFrame to the selected classes\n",
        "data.label.unique()\n",
        "\n",
        "lb = preprocessing.LabelEncoder() # encoding target labels with values between 0 and n_classes-1\n",
        "data['label'] = lb.fit_transform(data['label']) #  appling encoded labels to our DataFrame data\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      label                                         image_path\n",
            "1413      1  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1414      1  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1415      1  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1416      1  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n",
            "1417      1  /content/drive/MyDrive/DEEPVIS/data/WaferImage...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoGati1tO_p9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30d7c28-dc2e-41ed-9eee-f882c5616491"
      },
      "source": [
        "len(lb.classes_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSlE4W0UQZl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceaaf82-7ead-4c05-c079-30d6e525e922"
      },
      "source": [
        "mapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
        "inverse_mapping = dict(zip(lb.transform(lb.classes_), lb.classes_))\n",
        "\n",
        "print(\"Mapping label to class:\")\n",
        "print('\\n')\n",
        "print(inverse_mapping)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mapping label to class:\n",
            "\n",
            "\n",
            "{0: 'circle', 1: 'crack', 2: 'good', 3: 'scratch', 4: 'splinter', 5: 'stain'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHCJr5IFDctF"
      },
      "source": [
        "# Prepare Dataset into Train and Test Set (80:20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yed9nTLUVXJ"
      },
      "source": [
        "X = data.image_path\n",
        "y = data.label\n",
        "\n",
        "n_splits = 1  # A single split in this case\n",
        "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.20, random_state=42) \n",
        "\n",
        "for train_index, val_index in sss.split(X, y):\n",
        "  X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "  y_train, y_val = y.iloc[train_index], y.iloc[val_index]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IynS-DyeOQD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea7060e-9501-47e1-ea16-303e107f82f3"
      },
      "source": [
        "print(len(X), len(y))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3264 3264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXWZC0DZFVcy"
      },
      "source": [
        "Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8m9VeiFFOE",
        "outputId": "e9618422-1c7b-48b8-d2d8-0ae13721b808"
      },
      "source": [
        "# check if split correct\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_val))\n",
        "print(len(y_val))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2611\n",
            "2611\n",
            "653\n",
            "653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "2NyN0cJcFy5o",
        "outputId": "879ca7bc-d085-4ee0-f4b3-ef5f0824b58b"
      },
      "source": [
        "y_train.value_counts().plot(kind='bar', figsize=(14, 8)) # plotting the number of occurrences of each label"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5545c22c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAAHOCAYAAAChJicfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUEklEQVR4nO3dW6hlB33H8d9fp7FeIIlmCHEmOgGDkt7UDjGSUlrTSzTi+KCiLRokbV60ai2tU/vgUyFCaapQhGCUWKyXppakjWglasEWUycq3qJ1GhOTkOgoUavRauq/D2dFx2HinOmcc/b5dz4fGM667bP/h1kw5ztr7b2ruwMAADDVQ1Y9AAAAwIkQNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMtmPVAyTJGWec0Xv27Fn1GAAAwDZ18803f627dx5t37aImj179uTAgQOrHgMAANimqur2B9vn9jMAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIy2Y9UDbBd79t+w6hFW7rYrLln1CAAAcNxcqQEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADDauqKmqv6wqj5bVZ+pqndU1c9W1TlVdVNVHayqd1XVKcuxD1vWDy7792zmDwAAAJzcjhk1VbUrySuS7O3un0/y0CQvTPL6JFd29xOS3JvksuUhlyW5d9l+5XIcAADApljv7Wc7kjy8qnYkeUSSu5M8I8m1y/5rkjx3Wd63rGfZf1FV1caMCwAA8JOOGTXdfVeSv0jy5azFzDeT3JzkG919/3LYnUl2Lcu7ktyxPPb+5fjHbOzYAAAAa9Zz+9npWbv6ck6SxyZ5ZJKLT/SJq+ryqjpQVQcOHTp0ot8OAAA4Sa3n9rPfSPKl7j7U3T9I8p4kFyY5bbkdLUl2J7lrWb4rydlJsuw/NcnXj/ym3X1Vd+/t7r07d+48wR8DAAA4Wa0nar6c5IKqesTy2piLknwuyYeSPG855tIk1y3L1y/rWfZ/sLt740YGAAD4sfW8puamrL3g/+NJPr085qokr0ny6qo6mLXXzFy9POTqJI9Ztr86yf5NmBsAACDJ2ruaHVN3vy7J647YfGuS849y7PeSPP/ERwMAADi29b6lMwAAwLYkagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYbV1RU1WnVdW1VfX5qrqlqp5eVY+uqg9U1ReXr6cvx1ZVvbGqDlbVp6rqqZv7IwAAACez9V6peUOS93X3k5L8UpJbkuxPcmN3n5vkxmU9SZ6Z5Nzlz+VJ3rShEwMAABzmmFFTVacm+dUkVydJd3+/u7+RZF+Sa5bDrkny3GV5X5K39ZqPJjmtqs7a8MkBAACyvis15yQ5lOStVfWJqnpzVT0yyZndffdyzD1JzlyWdyW547DH37ls+wlVdXlVHaiqA4cOHfq//wQAAMBJbT1RsyPJU5O8qbufkuQ7+fGtZkmS7u4kfTxP3N1Xdffe7t67c+fO43koAADAj6wnau5Mcmd337SsX5u1yPnKA7eVLV+/uuy/K8nZhz1+97INAABgwx0zarr7niR3VNUTl00XJflckuuTXLpsuzTJdcvy9UlesrwL2gVJvnnYbWoAAAAbasc6j/uDJG+vqlOS3JrkpVkLondX1WVJbk/yguXY9yZ5VpKDSe5bjgUAANgU64qa7v5kkr1H2XXRUY7tJC87wbkAAADWZb2fUwMAALAtiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARhM1AADAaKIGAAAYTdQAAACjiRoAAGA0UQMAAIwmagAAgNFEDQAAMJqoAQAARtux6gFgO9mz/4ZVj7Byt11xyapHAAA4Lq7UAAAAo4kaAABgNFEDAACMJmoAAIDRvFEAwBG8YYQ3jABgFldqAACA0UQNAAAwmqgBAABG85oaADgKr63y2ipgDldqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABht3VFTVQ+tqk9U1T8t6+dU1U1VdbCq3lVVpyzbH7asH1z279mc0QEAAI7vSs0rk9xy2Prrk1zZ3U9Icm+Sy5btlyW5d9l+5XIcAADAplhX1FTV7iSXJHnzsl5JnpHk2uWQa5I8d1net6xn2X/RcjwAAMCGW++Vmr9K8idJfrisPybJN7r7/mX9ziS7luVdSe5IkmX/N5fjAQAANtwxo6aqnp3kq91980Y+cVVdXlUHqurAoUOHNvJbAwAAJ5H1XKm5MMlzquq2JO/M2m1nb0hyWlXtWI7ZneSuZfmuJGcnybL/1CRfP/KbdvdV3b23u/fu3LnzhH4IAADg5HXMqOnuP+3u3d29J8kLk3ywu383yYeSPG857NIk1y3L1y/rWfZ/sLt7Q6cGAABYnMjn1Lwmyaur6mDWXjNz9bL96iSPWba/Osn+ExsRAADgwe049iE/1t0fTvLhZfnWJOcf5ZjvJXn+BswGAABwTCdypQYAAGDlRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEbbseoBAAC2qz37b1j1CNvCbVdcsuoR4KdypQYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKMdM2qq6uyq+lBVfa6qPltVr1y2P7qqPlBVX1y+nr5sr6p6Y1UdrKpPVdVTN/uHAAAATl7ruVJzf5I/6u7zklyQ5GVVdV6S/Ulu7O5zk9y4rCfJM5Ocu/y5PMmbNnxqAACAxTGjprvv7u6PL8v/leSWJLuS7EtyzXLYNUmeuyzvS/K2XvPRJKdV1VkbPjkAAECO8zU1VbUnyVOS3JTkzO6+e9l1T5Izl+VdSe447GF3LtuO/F6XV9WBqjpw6NCh4xwbAABgzbqjpqoeleTvk7yqu791+L7u7iR9PE/c3Vd1997u3rtz587jeSgAAMCPrCtqqupnshY0b+/u9yybv/LAbWXL168u2+9KcvZhD9+9bAMAANhw63n3s0pydZJbuvsvD9t1fZJLl+VLk1x32PaXLO+CdkGSbx52mxoAAMCG2rGOYy5M8uIkn66qTy7bXpvkiiTvrqrLktye5AXLvvcmeVaSg0nuS/LSDZ0YAADgMMeMmu7+SJJ6kN0XHeX4TvKyE5wLAABgXY7r3c8AAAC2G1EDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRRA0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo4kaAABgNFEDAACMJmoAAIDRdqx6AAAA2O727L9h1SOs3G1XXLLqER6UKzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBoogYAABhN1AAAAKOJGgAAYDRRAwAAjCZqAACA0UQNAAAwmqgBAABGEzUAAMBomxI1VXVxVX2hqg5W1f7NeA4AAIBkE6Kmqh6a5K+TPDPJeUleVFXnbfTzAAAAJJtzpeb8JAe7+9bu/n6SdybZtwnPAwAAkOrujf2GVc9LcnF3/96y/uIkT+vulx9x3OVJLl9Wn5jkCxs6yDxnJPnaqodg5ZwHPMC5QOI8YI3zgMR5kCSP7+6dR9uxY6sneUB3X5XkqlU9/3ZTVQe6e++q52C1nAc8wLlA4jxgjfOAxHlwLJtx+9ldSc4+bH33sg0AAGDDbUbUfCzJuVV1TlWdkuSFSa7fhOcBAADY+NvPuvv+qnp5kvcneWiSt3T3Zzf6ef4fciseifOAH3MukDgPWOM8IHEe/FQb/kYBAAAAW2lTPnwTAABgq4gaAABgNFEDAACMtrLPqTnZVdWTkuxKclN3f/uw7Rd39/tWNxmrUlW/kuT8JJ/p7n9e9TzA1quq85N0d3+sqs5LcnGSz3f3e1c8Glto+R1hX9Z+T0jWPhrj+u6+ZXVTsWpV9bbufsmq59iuvFHAClTVK5K8LMktSZ6c5JXdfd2y7+Pd/dRVzsfWqKp/7+7zl+Xfz9o58Q9JfivJP3b3Faucj+2hql7a3W9d9Rxsvqp6XZJnZu0/HD+Q5GlJPpTkN5O8v7v/fIXjsUWq6jVJXpTknUnuXDbvztpHZLzTvw0nh6o68uNQKsmvJ/lgknT3c7Z8qG1O1KxAVX06ydO7+9tVtSfJtUn+prvfUFWf6O6nrHRAtsThf9dV9bEkz+ruQ1X1yCQf7e5fWO2EbAdV9eXuftyq52DzLf82PDnJw5Lck2R3d3+rqh6etav6v7jSAdkSVfUfSX6uu39wxPZTkny2u89dzWRspar6eJLPJXlzks5a1Lwja3Gb7v6X1U23Pbn9bDUe8sAtZ919W1X9WpJrq+rxWTtpOTk8pKpOz9pr26q7DyVJd3+nqu5f7Whspar61IPtSnLmVs7CSt3f3f+T5L6q+s/u/laSdPd3q+qHK56NrfPDJI9NcvsR289a9nFy2JvklUn+LMkfd/cnq+q7YubBiZrV+EpVPbm7P5kkyxWbZyd5SxL/O3/yODXJzVn7xbWr6qzuvruqHhVxe7I5M8lvJ7n3iO2V5N+2fhxW5PtV9Yjuvi/JLz+wsapOjV9mTyavSnJjVX0xyR3LtscleUKSl69sKrZUd/8wyZVV9XfL16/E7+0/ldvPVqCqdmftf+TuOcq+C7v7X1cwFttEVT0iyZnd/aVVz8LWqKqrk7y1uz9ylH1/292/s4Kx2GJV9bDu/u+jbD8jyVnd/ekVjMUKVNVDsvbGMYe/UcDHlit5nISq6pIkF3b3a1c9y3YlagAAgNF8Tg0AADCaqAEAAEYTNQAAwGiiBgAAGE3UAAAAo/0v5YZDeSN7K6YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "_TNti1UfF9aF",
        "outputId": "b2739fb6-e5d9-487f-96eb-16542121f468"
      },
      "source": [
        "y_val.value_counts().plot(kind='bar', figsize=(14, 8)) # plotting the number of occurrences of each label"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f55452b8350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnK5e7AoLOqN"
      },
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z79LNvBLalB"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evscwIrCNRbx"
      },
      "source": [
        "def load_image(infilename, infilegrayscale):\n",
        "    \"\"\"\n",
        "    This function loads an image into memory when you give it the path of the image\n",
        "    \"\"\"\n",
        "    if infilegrayscale:\n",
        "      img = Image.open(infilename).convert('L')\n",
        "    else:\n",
        "      img = Image.open(infilename)\n",
        "    #data = np.asarray(img)\n",
        "    return img"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7sNStzvMbV5"
      },
      "source": [
        "class WaferDataset(Dataset):\n",
        "    def __init__(self, path, labels, model=None):\n",
        "        self.X = path\n",
        "        self.y = labels\n",
        "        self.model = model\n",
        "        if self.model in [\"BaseNet\", \"RegNet\", \"VicNet\"]:\n",
        "          self.infilegrayscale = True\n",
        "        else:\n",
        "          self.infilegrayscale = False\n",
        "\n",
        "        # preprocessing\n",
        "        if model in [\"ResNet18\", \"VGG16\"]: # validation\n",
        "            self.preprocess = transforms.Compose([\n",
        "              transforms.Resize(244),\n",
        "              transforms.CenterCrop(224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # duplicate channel as Resnet18 based on RGB\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "              # Data augmentation\n",
        "              transforms.RandomHorizontalFlip(p=0.5),\n",
        "              transforms.RandomRotation(30),\n",
        "              transforms.RandomVerticalFlip(p=0.5)\n",
        "            ])\n",
        "        elif model in [\"BaseNet\", \"RegNet\", \"VicNet\", \"MaxNet\"]:\n",
        "          self.preprocess = transforms.Compose([\n",
        "              transforms.Resize(244),\n",
        "              transforms.CenterCrop(224),\n",
        "              transforms.ToTensor(),\n",
        "              # Data augmentation\n",
        "              transforms.RandomHorizontalFlip(p=0.5),\n",
        "              transforms.RandomRotation(30),\n",
        "              transforms.RandomVerticalFlip(p=0.5)\n",
        "            ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = load_image(self.X.iloc[i], self.infilegrayscale)\n",
        "        label = self.y.iloc[i]\n",
        "        if self.model is not None:\n",
        "          image = self.preprocess(image)\n",
        "        # print(image.shape)\n",
        "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP9gy1lucgvo"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05jsA8ZDVrTc"
      },
      "source": [
        "## Unregularized Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfaq69uiVzYn"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UtQ5LQ5V00M"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VhrBUwAVtAu"
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    # Here, we define all the weights for the neural network, they are abstracted by layers. Internally however, they are represented by Pytorch tensors.\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=config.kernel_size)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=config.kernel_size)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=config.kernel_size)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config.fc_layer_size)\n",
        "    self.fc2 = nn.Linear(in_features=config.fc_layer_size, out_features=len(lb.classes_))\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    return x\n",
        "  \n",
        "  def forward(self, x):\n",
        "      # Here, we define how an input x is translated into an output. In our linear example, this was simply (x^T * w), now it becomes more complex but\n",
        "      # we don't have to care about that (gradients etc. are taken care of by Pytorch).\n",
        "      x = self._forward_features(x)\n",
        "      # You can always print shapes and tensors here. This is very very helpful to debug.\n",
        "      # print(\"x.shape:\", x.shape)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulm4do8xV3Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4eb4d2-97cb-4a11-a542-7f00610946db"
      },
      "source": [
        "basenet = BaseNet()\n",
        "basenet = basenet.to(runtime)\n",
        "\n",
        "print(basenet)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BaseNet(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=86528, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5EgedoI5tcb"
      },
      "source": [
        "## Regularized Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hp1lfTQM_NG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFiVmYk5vSJ"
      },
      "source": [
        "class RegNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    # Here, we define all the weights for the neural network, they are abstracted by layers. Internally however, they are represented by Pytorch tensors.\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=config.kernel_size)\n",
        "    self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=config.kernel_size)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=config.kernel_size)\n",
        "    self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config.fc_layer_size)\n",
        "    self.fc2 = nn.Linear(in_features=config.fc_layer_size, out_features=len(lb.classes_))\n",
        "    \n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    self.dropout = nn.Dropout2d(config.dropout)\n",
        "\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "    return x\n",
        "  \n",
        "  def forward(self, x):\n",
        "      # Here, we define how an input x is translated into an output. In our linear example, this was simply (x^T * w), now it becomes more complex but\n",
        "      # we don't have to care about that (gradients etc. are taken care of by Pytorch).\n",
        "      x = self._forward_features(x)\n",
        "      # You can always print shapes and tensors here. This is very very helpful to debug.\n",
        "      # print(\"x.shape:\", x.shape)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D_NlFSi7cfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcda3ea7-4cd5-4315-cf0c-d0dca6168d63"
      },
      "source": [
        "regnet = RegNet()\n",
        "regnet = regnet.to(runtime)\n",
        "\n",
        "print(regnet)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RegNet(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=86528, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U099hsjBpxOA"
      },
      "source": [
        "## VicNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50X-zroWpw3K"
      },
      "source": [
        "class resBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "      super().__init__()\n",
        "      self.in_channels = in_channels\n",
        "      self.out_channels = out_channels\n",
        "      self.kernel_size = kernel_size\n",
        "      self.stride = stride\n",
        "      self.downsample = None\n",
        "\n",
        "      if stride != 1 or in_channels != out_channels:\n",
        "        self.downsample = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, 1, self.stride),\n",
        "                                        nn.BatchNorm2d(self.out_channels))\n",
        "\n",
        "      self.block = nn.Sequential(nn.Conv2d(self.in_channels, self.out_channels, self.kernel_size, self.stride, padding=1),\n",
        "                                nn.BatchNorm2d(self.out_channels),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(self.out_channels, self.out_channels, self.kernel_size, 1, padding=1),\n",
        "                                nn.BatchNorm2d(self.out_channels))\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "                               \n",
        "    def forward(self, x):\n",
        "      skip = x\n",
        "      x = self.block(x)\n",
        "      if self.downsample is not None:\n",
        "        skip = self.downsample(skip)\n",
        "      x += skip\n",
        "      x = self.relu(x)\n",
        "      return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfInPwMQqYTK"
      },
      "source": [
        "class VicNet(nn.Module):\n",
        "  def __init__(self, input_shape=(1, 224, 224)):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=config.kernel_size)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=config.kernel_size)\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
        "    self.dropout = nn.Dropout2d(config.dropout)\n",
        "    self.block1 = resBlock(in_channels=32, out_channels=32)\n",
        "    self.block2 = resBlock(in_channels=32, out_channels=64, stride=2)\n",
        "    self.block3 = resBlock(in_channels=64, out_channels=128, stride=2)\n",
        "    self.block4 = resBlock(in_channels=128, out_channels=256)\n",
        "    self.avg_pool = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "    n_size = self._get_conv_output(input_shape)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=n_size, out_features=config.fc_layer_size)\n",
        "    self.fc2 = nn.Linear(in_features=config.fc_layer_size, out_features=len(lb.classes_))\n",
        "\n",
        "  def _get_conv_output(self, shape):\n",
        "    batch_size = 1\n",
        "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "    output_feat = self._forward_features(input)\n",
        "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "    return n_size\n",
        "  \n",
        "  def _forward_features(self, x):\n",
        "    x = self.max_pool(F.relu(self.conv1(x)))\n",
        "    x = self.max_pool(F.relu(self.conv2(x)))\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.avg_pool(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._forward_features(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TB8u-Ges9nm",
        "outputId": "ce74bcdb-91f1-4340-b668-42527fcac053"
      },
      "source": [
        "vicnet = VicNet()\n",
        "vicnet = vicnet.to(runtime)\n",
        "\n",
        "print(vicnet)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VicNet(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
            "  (block1): resBlock(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block2): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block3): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (block4): resBlock(\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXqeCtojCJ7R"
      },
      "source": [
        "## MaxNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU0Q_s6GCJV6"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class ConnectionBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, stride):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pathA = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=3,\n",
        "                stride=stride,\n",
        "                padding=1),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathB = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=5,\n",
        "                stride=stride,\n",
        "                padding=2),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=5,\n",
        "                stride=1,\n",
        "                padding=2),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathC = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=9,\n",
        "                stride=stride,\n",
        "                padding=4),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=9,\n",
        "                stride=1,\n",
        "                padding=4),\n",
        "            nn.BatchNorm2d(num_features=out_c),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.pathSkip = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_c,\n",
        "                out_channels=out_c,\n",
        "                kernel_size=1,\n",
        "                stride=stride),\n",
        "            nn.BatchNorm2d(num_features=out_c))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pathA(x) + self.pathB(x) + self.pathC(x) + self.pathSkip(x)\n",
        "\n",
        "\n",
        "class MaxNet(nn.Module):\n",
        "    def __init__(self, out_classes=len(lb.classes_), input_shape=(1, 224, 224)):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            ConnectionBlock(in_c=64, out_c=64, stride=1),\n",
        "            ConnectionBlock(in_c=64, out_c=128, stride=2),\n",
        "            ConnectionBlock(in_c=128, out_c=256, stride=2),\n",
        "            ConnectionBlock(in_c=256, out_c=256, stride=2),\n",
        "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
        "            Flatten(),\n",
        "            nn.Linear(in_features=512*16, out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256, out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256, out_features=out_classes),\n",
        "            #nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tLRLdflCeSB",
        "outputId": "a00fdfc2-015f-4c4f-b60a-e6772d64f3ce"
      },
      "source": [
        "maxnet = MaxNet()\n",
        "maxnet = maxnet.to(runtime)\n",
        "\n",
        "print(maxnet)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MaxNet(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): ConnectionBlock(\n",
            "      (pathA): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathB): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathC): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (pathSkip): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "    (9): Flatten()\n",
            "    (10): Linear(in_features=8192, out_features=256, bias=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=256, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIwqSHsTMKSo"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-fbO2VhNDIJ"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CrGJGbWVSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0aa406-f0fb-4f00-b6a8-1660ee52e6d9"
      },
      "source": [
        "resnet18 = models.resnet18(pretrained=True)  \n",
        "for param in resnet18.parameters():\n",
        "  param.requires_grad=False # freezes the layers to only fine-tune the last one\n",
        "\n",
        "print(resnet18)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J88gzUWMMIn"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paQQGO8DWRBK"
      },
      "source": [
        "Also try VGG16 without batch norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngO0J3gJMIzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911571d3-66c8-40ec-b3a7-a94205d9be06"
      },
      "source": [
        "vgg16 = models.vgg16_bn(pretrained=True)\n",
        "for param in vgg16.features.parameters():\n",
        "  param.requires_grad=False # freezes the layers to only fine-tune the last one\n",
        "\n",
        "print(vgg16)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTjBLOixcu2Y"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51C8Avb0Su-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "da1962502aaf4b06b6f7a285fe8f571c",
            "769563887a7a44c7a65728dbfaa5aa5c",
            "15ec4fe9bb4d4e878da1ec7d69e5e0f3"
          ]
        },
        "outputId": "e0989ed0-5df9-41a9-aba4-2eea4b20785a"
      },
      "source": [
        "list_transfer_model = ['ResNet18', 'VGG16']\n",
        "\n",
        "w = widgets.Dropdown(options={'VicNet': vicnet,\n",
        "                              'ResNet18': resnet18, \n",
        "                              'VGG16': vgg16, \n",
        "                              'RegNet': regnet, \n",
        "                              'BaseNet': basenet, \n",
        "                              'MaxNet': maxnet})\n",
        "display(w)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da1962502aaf4b06b6f7a285fe8f571c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options={'VicNet': VicNet(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Con…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7nQo7zS_Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d21bffc-6089-448b-c0ef-22b46a312131"
      },
      "source": [
        "print(f'Selected Net: {w.label}')\n",
        "w.value"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected Net: VGG16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQJgEurThsbq"
      },
      "source": [
        "net = w.value"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OST25CGClRl"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eVUz9g-3bKD"
      },
      "source": [
        "To measuse inference time: https://towardsdatascience.com/the-correct-way-to-measure-inference-time-of-deep-neural-networks-304a54e5187f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_92yNmCw0qa"
      },
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfHC7bqMaku2"
      },
      "source": [
        "def train(config=None):\n",
        "  wandb.init(config=config_defaults)\n",
        "  config = wandb.config\n",
        "\n",
        "  early_stopping_counter = 0\n",
        "  epochs = config.epochs\n",
        "  if w.label in list_transfer_model:\n",
        "    transferlearning = True\n",
        "  else:\n",
        "    transferlearning = False\n",
        "\n",
        "  train_data = WaferDataset(X_train, y_train, model=w.label)\n",
        "  val_data = WaferDataset(X_val, y_val, model=w.label)\n",
        "    \n",
        "  # dataloaders\n",
        "  train_dataloader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)  # shuffle here instead of in model\n",
        "  val_dataloader = DataLoader(val_data, batch_size=config.batch_size, shuffle=False)\n",
        "\n",
        "  # Init the neural network\n",
        "  if transferlearning:\n",
        "    # Setup / deepcopy transfer learning model based on selected backbone transfer model \n",
        "    net = copy.deepcopy(w.value)\n",
        "    # Add Classifier Layer to backbone transfer model\n",
        "    net.fc = nn.Linear(config.fc_layer_size, len(lb.classes_))\n",
        "    # Model to Cuda\n",
        "    net = net.to(runtime)\n",
        "  else:\n",
        "    net = w.value\n",
        "    net.apply(reset_weights)\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  # Define the optimizer\n",
        "  if config.optimizer=='sgd':\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=config.learning_rate, momentum=0.9)\n",
        "  elif config.optimizer=='adam':\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=config.learning_rate)\n",
        "  elif config.optimizer=='adadelta':\n",
        "    optimizer = torch.optim.Adadelta(net.parameters(), lr=config.learning_rate, rho=0.9, eps=1e-06, weight_decay=0)\n",
        "\n",
        "  loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  train_acc = []\n",
        "  val_acc = []\n",
        "  acc_val = 0\n",
        "  acc_train = 0\n",
        "  batch_ct = 0\n",
        "  example_ct = 0\n",
        "\n",
        "\n",
        "  starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "  timings=[]\n",
        "  frames = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # This command tells the neural network that it should be in training-mode now.\n",
        "    # This call is important as some functions in neural networks (e.g., dropout) should \n",
        "    # only be applied when training\n",
        "    net.train()\n",
        "\n",
        "    total=0\n",
        "    correct=0\n",
        "\n",
        "    epoch_train_loss = 0.\n",
        "    # Iterate over the dataset in chunks of size 32 (the batches)\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "      X_batch, y_batch = data[0].to(runtime), data[1].to(runtime)\n",
        "\n",
        "      y_pred = net(X_batch)\n",
        "      loss = loss_fct(y_pred, y_batch)\n",
        "\n",
        "      example_ct += len(data)\n",
        "\n",
        "      epoch_train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "      _,pred = torch.max(y_pred, dim=1)\n",
        "\n",
        "      #add the count of correct prediction of the batch to a correct prediction list\n",
        "      correct += torch.sum(pred==y_batch).item()\n",
        "      #add the count of all predictions of the batch to a total prediction list\n",
        "      total += y_batch.size(0)\n",
        "      #calculate accuracy of all predicted samples so far\n",
        "      acc_train = 100 * correct/total\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    epoch_train_loss = epoch_train_loss / len(train_dataloader.sampler)\n",
        "    wandb.log({\"epoch\": epoch, \"train_loss\": epoch_train_loss, \"train_accuracy\": acc_train})\n",
        "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {epoch_train_loss:.3f}\")\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_acc.append(acc_train)\n",
        "\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "\n",
        "    # Init or reset the prediction and label lists(tensors) of a epoch\n",
        "    predlist=torch.zeros(0,dtype=torch.long, device=runtime)\n",
        "    lbllist=torch.zeros(0,dtype=torch.long, device=runtime)\n",
        "\n",
        "\n",
        "    epoch_val_loss = 0. #reset epoch loss from validation\n",
        "\n",
        "    # This command tells the neural network that it should be in evaluation mode now.\n",
        "    # This call turns of special functions for training, such as dropout. \n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for X_batch_val, y_batch_val in (val_dataloader):\n",
        "        #load batch of validation data\n",
        "        X_batch_val, y_batch_val = X_batch_val.to(runtime), y_batch_val.to(runtime)\n",
        "\n",
        "        #predict batch\n",
        "        starter.record()\n",
        "        y_pred_val = net(X_batch_val)\n",
        "        ender.record()\n",
        "\n",
        "        if runtime == torch.device('cuda'):\n",
        "            torch.cuda.synchronize() \n",
        "\n",
        "        laps_time = starter.elapsed_time(ender)\n",
        "        \n",
        "        timings.append(laps_time / X_batch_val.size(0))\n",
        "        frames.append(X_batch_val.size(0) / laps_time)\n",
        "\n",
        "        \n",
        "        loss_val = loss_fct(y_pred_val.squeeze(), y_batch_val)\n",
        "        # append loss of batch to epoch loss\n",
        "        epoch_val_loss += loss_val.item() * X_batch_val.size(0)\n",
        "                                              \n",
        "        _,pred_t = torch.max(y_pred_val, dim=1)\n",
        "\n",
        "        #add the count of correct prediction of the batch to a correct prediction list\n",
        "        correct_t += torch.sum(pred_t==y_batch_val).item()\n",
        "        #add the count of all predictions of the batch to a total prediction list\n",
        "        total_t += y_batch_val.size(0)\n",
        "        #calculate accuracy of all predicted samples so far\n",
        "        acc_val = 100 * correct_t/total_t\n",
        "\n",
        "        # Concatenate the prediction of a batch to list of all prediction of a epoch\n",
        "        predlist=torch.cat([predlist,pred_t.view(-1).to(runtime)])\n",
        "        lbllist=torch.cat([lbllist,y_batch_val.view(-1).to(runtime)])\n",
        "\n",
        "      # log the test accuracy\n",
        "      wandb.log({\"val_loss\": epoch_val_loss / len(val_dataloader.sampler), \"val_accuracy\": acc_val})\n",
        "\n",
        "\n",
        "      epoch_val_loss = epoch_val_loss / len(val_dataloader.sampler)\n",
        "      val_losses.append(epoch_val_loss)\n",
        "      val_acc.append(acc_val)\n",
        "      print('Avg execution time (ms): {:.3f}'.format(np.mean(timings)))\n",
        "      print('Avg frames per seconds (fps): {:.3f}'.format(np.mean(frames)))\n",
        "      print('Epoch: {} ->  Train loss: {} Val loss: {} Train Accuracy: {} Val Accuracy: {}'.format(epoch, epoch_train_loss, epoch_val_loss, acc_train, acc_val))\n",
        "\n",
        "\n",
        "  y_true = lbllist.cpu().numpy()\n",
        "  y_pred = predlist.cpu().numpy()\n",
        "\n",
        "  # Confusion matrix\n",
        "  conf_mat=confusion_matrix(y_true, y_pred)\n",
        "  print('\\n')\n",
        "  print(f'Total Prediction: {len(predlist)}')\n",
        "  print(f'Correct Prediction: {sum(conf_mat.diagonal())}')\n",
        "  print('Confusion matrix')\n",
        "  print(conf_mat)\n",
        "  print('\\n')\n",
        "\n",
        "  # Precision, Recall, F1-score\n",
        "  class_report_print = classification_report(y_true, y_pred)\n",
        "  print(class_report_print)\n",
        "\n",
        "  # Per-class accuracy\n",
        "  class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "  overall_accuracy = 100 * sum(conf_mat.diagonal()) / len(predlist)\n",
        "  print(f'Per-class accuracy: {class_accuracy}')\n",
        "  print(f'Overall accuracy: {overall_accuracy}')\n",
        "  print('\\n')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqx8CoQBv_XH"
      },
      "source": [
        "## Run the sweep agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsysrn22v-2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6c1e149-39b3-4f70-bafd-a0bc7850e686"
      },
      "source": [
        "wandb.agent(sweep_id, train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bw7dplm2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.0<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">unique-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/inceptioneers/waferimages-sweeps\" target=\"_blank\">https://wandb.ai/inceptioneers/waferimages-sweeps</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/inceptioneers/waferimages-sweeps/sweeps/nygp64a8\" target=\"_blank\">https://wandb.ai/inceptioneers/waferimages-sweeps/sweeps/nygp64a8</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/inceptioneers/waferimages-sweeps/runs/bw7dplm2\" target=\"_blank\">https://wandb.ai/inceptioneers/waferimages-sweeps/runs/bw7dplm2</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210817_203258-bw7dplm2</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after 00082 examples: 2.730\n",
            "Avg execution time (ms): 5.486\n",
            "Avg frames per seconds (fps): 0.182\n",
            "Epoch: 0 ->  Train loss: 2.730066133065956 Val loss: 1.3494476992722493 Train Accuracy: 30.86939869781693 Val Accuracy: 50.995405819295556\n",
            "Loss after 00164 examples: 1.375\n",
            "Avg execution time (ms): 5.145\n",
            "Avg frames per seconds (fps): 0.195\n",
            "Epoch: 1 ->  Train loss: 1.3749519397544934 Val loss: 1.0591117792618767 Train Accuracy: 50.248946763692075 Val Accuracy: 65.08422664624808\n",
            "Loss after 00246 examples: 1.127\n",
            "Avg execution time (ms): 5.036\n",
            "Avg frames per seconds (fps): 0.199\n",
            "Epoch: 2 ->  Train loss: 1.1273092546028363 Val loss: 0.9361989329273814 Train Accuracy: 59.51742627345845 Val Accuracy: 69.52526799387442\n",
            "Loss after 00328 examples: 0.977\n",
            "Avg execution time (ms): 4.979\n",
            "Avg frames per seconds (fps): 0.202\n",
            "Epoch: 3 ->  Train loss: 0.9766462959352009 Val loss: 0.8412831378202161 Train Accuracy: 64.87935656836461 Val Accuracy: 71.36294027565084\n",
            "Loss after 00410 examples: 0.908\n",
            "Avg execution time (ms): 4.942\n",
            "Avg frames per seconds (fps): 0.203\n",
            "Epoch: 4 ->  Train loss: 0.9078121459470403 Val loss: 0.7954755116932972 Train Accuracy: 67.71351972424358 Val Accuracy: 71.66921898928024\n",
            "Loss after 00492 examples: 0.851\n",
            "Avg execution time (ms): 4.920\n",
            "Avg frames per seconds (fps): 0.204\n",
            "Epoch: 5 ->  Train loss: 0.850980096167415 Val loss: 0.7307247447383349 Train Accuracy: 69.43699731903486 Val Accuracy: 73.50689127105666\n",
            "Loss after 00574 examples: 0.794\n",
            "Avg execution time (ms): 4.904\n",
            "Avg frames per seconds (fps): 0.204\n",
            "Epoch: 6 ->  Train loss: 0.7935861104158367 Val loss: 0.7094993738722838 Train Accuracy: 72.92225201072387 Val Accuracy: 75.49770290964778\n",
            "Loss after 00656 examples: 0.769\n",
            "Avg execution time (ms): 4.890\n",
            "Avg frames per seconds (fps): 0.205\n",
            "Epoch: 7 ->  Train loss: 0.7685394380477049 Val loss: 0.6687510409727578 Train Accuracy: 71.39027192646496 Val Accuracy: 77.947932618683\n",
            "Loss after 00738 examples: 0.762\n",
            "Avg execution time (ms): 4.881\n",
            "Avg frames per seconds (fps): 0.205\n",
            "Epoch: 8 ->  Train loss: 0.7621053396308618 Val loss: 0.6916449834887868 Train Accuracy: 72.65415549597856 Val Accuracy: 76.41653905053599\n",
            "Loss after 00820 examples: 0.684\n",
            "Avg execution time (ms): 4.874\n",
            "Avg frames per seconds (fps): 0.206\n",
            "Epoch: 9 ->  Train loss: 0.6836428080240642 Val loss: 0.6455225352123722 Train Accuracy: 75.06702412868633 Val Accuracy: 78.25421133231241\n",
            "Loss after 00902 examples: 0.655\n",
            "Avg execution time (ms): 4.868\n",
            "Avg frames per seconds (fps): 0.206\n",
            "Epoch: 10 ->  Train loss: 0.6545422417092077 Val loss: 0.631754999184499 Train Accuracy: 76.29260819609345 Val Accuracy: 77.0290964777948\n",
            "Loss after 00984 examples: 0.629\n",
            "Avg execution time (ms): 4.862\n",
            "Avg frames per seconds (fps): 0.206\n",
            "Epoch: 11 ->  Train loss: 0.6291518214332423 Val loss: 0.6045761811240343 Train Accuracy: 77.82458828035236 Val Accuracy: 77.4885145482389\n",
            "Loss after 01066 examples: 0.641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azeQB23tixBW"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lngoMENpiyd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "ec64a6ce-9729-49f7-f032-d67194487fdf"
      },
      "source": [
        "SAVE_MODEL_PATH = \"/content/drive/MyDrive/DEEPVIS/models\"\n",
        "#torch.save(net.state_dict(), SAVE_MODEL_PATH)\n",
        "torch.save(net.state_dict(), os.path.join(SAVE_MODEL_PATH, w.label+'.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8adb84a90229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSAVE_MODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/DEEPVIS/models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#torch.save(net.state_dict(), SAVE_MODEL_PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DEEPVIS/models/VicNet.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRLMnPgpiztW"
      },
      "source": [
        "from pathlib import Path\n",
        "my_path= '/content/drive/MyDrive/DEEPVIS/'\n",
        "\n",
        "model = RegNet()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(copy.deepcopy(torch.load(Path(my_path + 'models/RegNet.pth'),device)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}